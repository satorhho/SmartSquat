{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd927b4-101a-4db9-8c66-0ac12f7d6a41",
   "metadata": {},
   "source": [
    "#Make sure to have a directory named \"cnn_inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd686435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image as imagekeras\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adec777-1d92-4942-856f-01d55aa9629d",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8130a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "recording = []\n",
    "segPose = []\n",
    "recPose = []\n",
    "\n",
    "str_feed = [\"Look forward\", \"Keep your foot flat\", \"Point knees outward\", \"Keep your torso upright\", \"Squat Lower\"]\n",
    "\n",
    "dir_path =f'{os.path.abspath(os.getcwd())}/cnn_inputs'\n",
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1c858a-4ba1-4c03-9d50-c67f54fdb64e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c90064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentize(recording_arr):\n",
    "  segments.append(recording_arr[0]) # top_1\n",
    "  segPose.append(recPose[0])\n",
    "  \n",
    "  prev_frame_yval = round(recording_arr[0][1], 1) # NOTE: The 2 index here is he 2nd decimal place\n",
    "  change_idx = 0\n",
    "\n",
    "  next_frame_yval = round(recording_arr[len(recording_arr)-2][1], 1)\n",
    "  change_idx_bot = 0\n",
    "\n",
    "  for i in range(len(recording_arr)):\n",
    "    if round(recording_arr[i][1], 1) > prev_frame_yval: # This is where the change starts from top_1 \n",
    "      change_idx = i\n",
    "      break\n",
    "\n",
    "  for j in range(len(recording_arr)):\n",
    "    if round(recording_arr[j][1], 1) == next_frame_yval: # This is where the change starts to bot_1\n",
    "      change_idx_bot = j\n",
    "      break\n",
    "\n",
    "  segments.append(recording_arr[math.floor((change_idx_bot + change_idx)/2)]) # mid_1\n",
    "  segments.append(recording_arr[len(recording_arr)-2]) # bot_1\n",
    "  segPose.append(recPose[math.floor((change_idx_bot + change_idx)/2)])\n",
    "  segPose.append(recPose[len(recording_arr)-2])\n",
    "\n",
    "  print(\"Segmentized!\")\n",
    "  return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d30bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs():\n",
    "  counter = 0\n",
    "  for i in segments:\n",
    "    cv.imwrite(f\"{os.path.abspath(os.getcwd())}/cnn_inputs/input{counter}.png\", i[0])\n",
    "    counter += 1\n",
    "\n",
    "  print(\"Images saved!\")\n",
    "  recording.clear()\n",
    "  segments.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fdb91-5256-46c0-ab49-1f09017321bd",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7913dbeb-f0b3-4255-bced-faae30cef057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_imgs():\n",
    "  predictions = []\n",
    "  for i in range(4):\n",
    "    img = imagekeras.load_img(f\"{dir_path}/input{i}.png\", target_size = (224, 224, 3))\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    X = imagekeras.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis = 0)\n",
    "    images = np.vstack([X])\n",
    "\n",
    "    val = model.predict(images)\n",
    "    class_names = {0 : 'c_bot_1', 1 :'c_mid_1', 2 :'c_top_1', 3 :'c_top_2', 4 :'i_bot_1', 5 :'i_mid_1', 6 :'i_top_1', 7 :'i_top_2'}\n",
    "    scores = tensorflow.nn.softmax(val[0])\n",
    "    scores = scores.numpy()\n",
    "    result = f\"{class_names[np.argmax(scores)]} with a { (100 *       np.max(scores)).round(2) } % confidence.\" \n",
    "    predictions.append(f\"{class_names[np.argmax(scores)]}\")\n",
    "    print(f\"{class_names[np.argmax(scores)]}\")\n",
    "  files = next(os.walk(dir_path), (None, None, []))[2]\n",
    "  for file in files: \n",
    "    os.remove(f\"{dir_path}/{file}\")\n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6579d2c8-2d11-440b-a923-7c7a2ceddfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage():\n",
    "  img = imagekeras.load_img(\"input.png\", target_size = (224, 224, 3))\n",
    "\n",
    "  X = imagekeras.img_to_array(img)\n",
    "  X = np.expand_dims(X, axis = 0)\n",
    "  images = np.vstack([X])\n",
    "\n",
    "  val = model.predict(images)\n",
    "  class_names = {0 : 'c_bot_1', 1 :'c_mid_1', 2 :'c_top_1', 3 :'c_top_2', 4 :'i_bot_1', 5 :'i_mid_1', 6 :'i_top_1', 7 :'i_top_2'}\n",
    "  scores = tensorflow.nn.softmax(val[0])\n",
    "  scores = scores.numpy()\n",
    "  result = f\"{class_names[np.argmax(scores)]} with a { (100 *       np.max(scores)).round(2) } % confidence.\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e5dc0f-2a08-494e-9048-5eec62c77770",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afc58cb8-4f54-41eb-bb32-f3c70570feee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal(x1, x2, x3):\n",
    "  return ((x2-x1) * (x3-x1))\n",
    "\n",
    "def distance3d(x1, y1, z1, x2, y2, z2):\n",
    "  x = (x2-x1) ** 2\n",
    "  y = (y2-y1) ** 2\n",
    "  z = (z2-z1) ** 2\n",
    "  return math.sqrt( x + y + z )\n",
    "\n",
    "def distance2d(x1, y1, x2, y2):\n",
    "    x = x1 - x2\n",
    "    y = y1 - y2\n",
    "    return x **2 + y ** 2\n",
    "     \n",
    "def angle2d(x1, y1, x2, y2, x3,y3):\n",
    "  \n",
    "  # Square of lengths be a2, b2, c2\n",
    "  a2 = distance2d(x2, y2, x3, y3)\n",
    "  b2 = distance2d(x1, y1, x3, y3)\n",
    "  c2 = distance2d(x1, y1, x2, y2)\n",
    "\n",
    "  # length of sides be a, b, c\n",
    "  a = math.sqrt(a2);\n",
    "  b = math.sqrt(b2);\n",
    "  c = math.sqrt(c2);\n",
    "\n",
    "  # From Cosine law\n",
    "  angle = math.acos((a2 + c2 - b2) /\n",
    "                     (2 * a * c));\n",
    "  # Converting to degree\n",
    "  angle = angle * 180 / math.pi;\n",
    "  \n",
    "  return angle\n",
    "\n",
    "def slope3d(x1, y1, z1, x2, y2, z2):\n",
    "  \n",
    "  deltaX = ((x1 - x2) **2)\n",
    "  deltaY = (y1 - y2) \n",
    "  deltaZ = ((z1 - z2) ** 2) \n",
    "  offset = math.sqrt( deltaZ + deltaX)\n",
    "  \n",
    "  return ( deltaY / offset)\n",
    "\n",
    "def angle3d(x1, y1, z1, x2, y2, z2, x3, y3, z3):\n",
    "  \n",
    "  # Numerator\n",
    "  num = (cal(x2, x1, x3) \n",
    "          + cal(y2, y1, y3) \n",
    "          + cal(z2, z1, z3))\n",
    "  #Denominator\n",
    "  e1 = distance3d(x2, y2, z2, x1, y1, z1)\n",
    "  e2 = distance3d(x2, y2, z2, x3, y3, z3)\n",
    "  \n",
    "  den = e1 * e2\n",
    "  angle = math.acos(num / den)\n",
    "\n",
    "  return angle * 180 / math.pi\n",
    "\n",
    "\n",
    "def lmPosition(pose, ctr):\n",
    "  x = pose.landmark[ctr].x\n",
    "  y = pose.landmark[ctr].y\n",
    "  z = pose.landmark[ctr].z\n",
    "  return [x,y,z]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25ba38-c454-4e7d-873b-56a7e7a594f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Posture Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb96dce3-427e-4f34-bf1e-3cf6fdf8bd18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remember, the functions should return true if the postures are correct\n",
    "\n",
    "def HeadAli(pose):\n",
    "  eyeOuter = lmPosition(pose, 3)\n",
    "  ear = lmPosition(pose, 7)\n",
    "  slope = slope3d(ear[0], ear[1], ear[2], \n",
    "                  eyeOuter[0], eyeOuter[1], eyeOuter[2])\n",
    "  print(f\"Head - {slope}\")\n",
    "  if(slope > 0.03):\n",
    "    return True\n",
    "  else : \n",
    "    return False\n",
    "  \n",
    "\n",
    "def FlatFoot(pose):\n",
    "  leftHeel = lmPosition(pose, 30)\n",
    "  leftFootidx = lmPosition(pose, 32)\n",
    "  rightHeel = lmPosition(pose, 29)\n",
    "  rightFootidx = lmPosition(pose, 31)\n",
    "  \n",
    "\n",
    "  \n",
    "  # if( leftHeel[0] > leftFootidx[0]):\n",
    "  l_slope = 100 * slope3d(leftFootidx[0], leftFootidx[1], leftFootidx[2], \n",
    "              leftHeel[0], leftHeel[1], leftHeel[2])\n",
    "  # else:\n",
    "  # l_slope = 100 * slope3d(leftHeel[0], leftHeel[1], leftHeel[2], \n",
    "  #               leftFootidx[0], leftFootidx[1], leftFootidx[2])\n",
    "    \n",
    "  print(f\"l_slope - {l_slope}\")\n",
    "  if(l_slope < 35 ):                      #checks if right feet is flat\n",
    "    return True                      #if flat, return true\n",
    "  else :\n",
    "    return False\n",
    "\n",
    "def TorsoAngle(top1, pose):\n",
    "  top_leftShoulder = lmPosition(top1, 12)\n",
    "  top_leftHip = lmPosition(top1, 24)\n",
    "  leftShoulder = lmPosition(pose, 12)\n",
    "  leftHip = lmPosition(pose, 24)\n",
    "  # leftKnee = lmPosition(pose, 26)\n",
    "  Tslope = 100 * slope3d(top_leftHip[0], top_leftHip[1], top_leftHip[2], \n",
    "                top_leftShoulder[0], top_leftShoulder[1], top_leftShoulder[2])\n",
    "  \n",
    "  slope = 100 * slope3d(leftHip[0], leftHip[1], leftHip[2], \n",
    "                leftShoulder[0], leftShoulder[1], leftShoulder[2])\n",
    "  \n",
    "  # angle = angle3d(leftKnee[0], leftKnee[1], leftKnee[2],\n",
    "  #                 leftHip[0], leftHip[1], leftHip[2],\n",
    "  #                 leftShoulder[0], leftShoulder[1], leftShoulder[2])\n",
    "  \n",
    "  # if(i == 1 or i==2):\n",
    "  #   slope = 1000 * slope3d(leftShoulder[0], leftShoulder[1], leftShoulder[2], \n",
    "  #                 leftHip[0], leftHip[1], leftHip[2])\n",
    "  #   if(slope > top):\n",
    "  #     return true\n",
    "  print(f\"top1 - {Tslope}\\n mid/bot - {slope}\")\n",
    "  if (Tslope > slope) and (slope > 90) :\n",
    "    return True\n",
    "  else : \n",
    "    return False\n",
    "\n",
    "def depth(pose):\n",
    "  leftHip = lmPosition(pose, 24)\n",
    "  leftKnee = lmPosition(pose, 26)\n",
    "  leftAnkle = lmPosition(pose, 28)\n",
    "  \n",
    "  angle = angle2d(leftAnkle[0], leftAnkle[1], \n",
    "                  leftKnee[0], leftKnee[1],\n",
    "                  leftHip[0], leftHip[1])\n",
    "  \n",
    "#   angle = angle_triangle2(leftHip[0], leftHip[1], leftHip[2], \n",
    "#                   leftKnee[0], leftKnee[1], leftKnee[2],\n",
    "#                   leftAnkle[0], leftAnkle[1], leftAnkle[2])\n",
    "\n",
    "\n",
    "#   if(i == 1 or i==2):\n",
    "#   leftHip = lmPosition(pose, 23)\n",
    "#   leftKnee = lmPosition(pose, 25)\n",
    "#   leftAnkle = lmPosition(pose, 27)\n",
    "  \n",
    "#   angle = angle3d(leftKnee[0], leftKnee[1], leftKnee[2], \n",
    "#                   leftAnkle[0], leftAnkle[1], leftAnkle[2],\n",
    "#                   leftHip[0], leftHip[1], leftHip[2])\n",
    "  print(f\"Depth - {angle}\")\n",
    "  if(angle < 75) :\n",
    "    return True\n",
    "  else : \n",
    "    return False\n",
    "\n",
    "\n",
    "def kneeCaveIn(pose):\n",
    "  rightKnee = lmPosition(pose, 25)\n",
    "  leftKnee = lmPosition(pose, 26)\n",
    "  rightFootidx = lmPosition(pose, 31)\n",
    "  leftFootidx = lmPosition(pose, 32)\n",
    "\n",
    "  disKnee = distance3d(rightKnee[0], rightKnee[1], rightKnee[2], leftKnee[0], leftKnee[1], leftKnee[2])\n",
    "\n",
    "  disFI = distance3d(rightFootidx[0], rightFootidx[1], rightFootidx[2],leftFootidx[0], leftFootidx[1], leftFootidx[2])\n",
    "  \n",
    "  print(f\"disKnee - {disKnee}\\n disFI - {disFI}\")\n",
    "  if(disKnee > (disFI/2) ) :\n",
    "    return True\n",
    "  else : \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9b0e76-6c79-472a-be76-ccfc2d6758a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feedback(poses): \n",
    "  pred = predict_imgs()\n",
    "  Head = True\n",
    "  Foot = True\n",
    "  Knee = True\n",
    "  Torso = True\n",
    "  Depth = True\n",
    "  seg = [\"c_top_1\", \"c_mid_1\", \"c_bot_1\", \"c_top_2\"]\n",
    "  for i in range (4):\n",
    "    if(pred[i] != seg[i]):\n",
    "      Head = Head and HeadAli(poses[i])\n",
    "      Foot = Foot and FlatFoot(poses[i])\n",
    "      Knee = Knee and kneeCaveIn(poses[i])\n",
    "      if(i == 1 or i == 2):\n",
    "        Torso =  Torso and TorsoAngle(poses[0], poses[i])\n",
    "        if(i == 2):\n",
    "          Depth = Depth and depth(poses[i])\n",
    "    print(\"\")\n",
    "  return [Head, Foot, Knee, Torso, Depth]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95105bdd-320e-451b-a0bc-54a780856e22",
   "metadata": {},
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a3143df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_top_2\n",
      "i_bot_1\n",
      "Head - -0.06966360690677408\n",
      "l_slope - 65.99501661261884\n",
      "disKnee - 0.3036443453921942\n",
      " disFI - 0.19855427996894479\n",
      "\n",
      "disKnee - 0.3036443453921942\n",
      " disFI - 0.19855427996894479\n",
      "top1 - 36.35583221406364\n",
      " mid/bot - 36.35583221406364\n",
      "\n",
      "disKnee - 0.3161900984133666\n",
      " disFI - 0.2585759470760954\n",
      "Depth - 174.60891807487357\n",
      "\n",
      "disKnee - 0.10956405994734605\n",
      " disFI - 0.2499853222518413\n",
      "\n",
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "Head - 0.12746009667123898\n",
      "l_slope - 6.584911176787996\n",
      "disKnee - 0.41720128703590487\n",
      " disFI - 0.7329703324186149\n",
      "\n",
      "Head - 0.12746009667123898\n",
      "l_slope - 6.584911176787996\n",
      "disKnee - 0.41720128703590487\n",
      " disFI - 0.7329703324186149\n",
      "top1 - 1092.3429636755984\n",
      " mid/bot - 1092.3429636755984\n",
      "\n",
      "Head - 0.04332177868934209\n",
      "l_slope - 57.9029450739012\n",
      "disKnee - 0.13216680484662893\n",
      " disFI - 0.3139308591275104\n",
      "Depth - 171.68347167284622\n",
      "\n",
      "Head - 0.058225680257323914\n",
      "\n",
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "Head - 0.13474409412347285\n",
      "l_slope - 7.470910306157491\n",
      "disKnee - 0.4008471177395119\n",
      " disFI - 0.6767173101878773\n",
      "\n",
      "Head - 0.1627421687639144\n",
      "l_slope - 17.14397963880005\n",
      "disKnee - 0.30917720596632126\n",
      " disFI - 0.37750627513781626\n",
      "top1 - 922.6674236945532\n",
      " mid/bot - 526.4142494148589\n",
      "\n",
      "Head - 0.3207199110683165\n",
      "l_slope - 25.066434411699117\n",
      "disKnee - 0.3178892512442939\n",
      " disFI - 0.24512431191679665\n",
      "top1 - 922.6674236945532\n",
      " mid/bot - 221.40208962762372\n",
      "Depth - 49.51097218685215\n",
      "\n",
      "Head - 0.1177008643676014\n",
      "l_slope - 9.162333457086955\n",
      "disKnee - 0.2520891858535446\n",
      " disFI - 0.44840105743684555\n",
      "\n",
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "Head - 0.09269890737151615\n",
      "l_slope - 59.4666813441834\n",
      "disKnee - 0.29497796286233313\n",
      " disFI - 0.16132123363931228\n",
      "\n",
      "Head - 0.09269890737151615\n",
      "disKnee - 0.29497796286233313\n",
      " disFI - 0.16132123363931228\n",
      "top1 - 42.40724960358011\n",
      " mid/bot - 42.40724960358011\n",
      "\n",
      "Head - 0.03183022976868113\n",
      "disKnee - 0.3019868577986342\n",
      " disFI - 0.22312323487804483\n",
      "Depth - 175.01235995828645\n",
      "\n",
      "Head - -0.02188863816929904\n",
      "disKnee - 0.28478264747053145\n",
      " disFI - 0.2616574100333652\n",
      "\n",
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "Head - 0.11417721987480484\n",
      "l_slope - 66.90014408917698\n",
      "disKnee - 0.1864950734364649\n",
      " disFI - 0.23069511876052393\n",
      "\n",
      "Head - 0.11417721987480484\n",
      "disKnee - 0.1864950734364649\n",
      " disFI - 0.23069511876052393\n",
      "top1 - 105.86379579320855\n",
      " mid/bot - 105.86379579320855\n",
      "\n",
      "Head - 0.11417721987480484\n",
      "disKnee - 0.1864950734364649\n",
      " disFI - 0.23069511876052393\n",
      "Depth - 175.40029774030512\n",
      "\n",
      "Head - 0.11417721987480484\n",
      "disKnee - 0.1864950734364649\n",
      " disFI - 0.23069511876052393\n",
      "\n",
      "Segmentized!\n",
      "Images saved!\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "i_bot_1\n",
      "Head - -0.034521108768913886\n",
      "l_slope - 35.37895307552444\n",
      "disKnee - 0.525816693960399\n",
      " disFI - 0.3329594888079029\n",
      "\n",
      "disKnee - 0.525816693960399\n",
      " disFI - 0.3329594888079029\n",
      "top1 - 53.01797107128249\n",
      " mid/bot - 53.01797107128249\n",
      "\n",
      "disKnee - 0.3963781274610319\n",
      " disFI - 0.5823050944421205\n",
      "Depth - 172.1546570729536\n",
      "\n",
      "disKnee - 0.41885121882895243\n",
      " disFI - 0.5028156464064257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pose estimation drawing utilities\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "\n",
    "# One time camera snapshot\n",
    "camera = cv.VideoCapture(0, cv.CAP_DSHOW)\n",
    "_, cam_frame = camera.read()\n",
    "camera.release()\n",
    "cv.destroyAllWindows()\n",
    "cam_shape = cam_frame.shape\n",
    "\n",
    "# Recording ulitilites\n",
    "prev_img = np.zeros(cam_shape)\n",
    "\n",
    "# timer utilities\n",
    "initial_time = time.time()\n",
    "initial_time2 = time.time()\n",
    "initial_ankle_pos = 0.01\n",
    "isTimed = False\n",
    "isRecording = False\n",
    "camera = cv.VideoCapture(0, cv.CAP_DSHOW)\n",
    "tmp_lmval =  0.1\n",
    "\n",
    "monitor_val = 0.01\n",
    "isTracking = False\n",
    "rec_this = 0\n",
    "feed = \"\"\n",
    "predictImage()\n",
    "\n",
    "while True:\n",
    "  \n",
    "  ret, frame = camera.read()\n",
    "\n",
    "  imgRGB = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "  results = pose.process(imgRGB)\n",
    "    \n",
    "  if results.pose_landmarks:\n",
    "    mpDraw.draw_landmarks(frame, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "    \n",
    "    if time.time() >= initial_time2 :\n",
    "      res = [True, True, True, True, True]\n",
    "      squatPrompt = \"Get Ready\"\n",
    "      \n",
    "      for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        h, w, c = frame.shape\n",
    "\n",
    "        if id == 11: \n",
    "          tmp_lmval = round(lm.x, 1)\n",
    "\n",
    "        if (not isTimed): # Set timer for 2 seconds\n",
    "\n",
    "          initial_time = time.time()\n",
    "          if id == 11: \n",
    "            initial_ankle_pos = round(lm.x, 1)\n",
    "        else: \n",
    "          if time.time() >= initial_time2 + 1 :\n",
    "            if time.time() >= initial_time + 1.5:\n",
    "              isRecording = True\n",
    "              squatPrompt = \"Please Squat Now\"\n",
    "\n",
    "\n",
    "        if tmp_lmval == initial_ankle_pos: \n",
    "          isTimed = True\n",
    "        else:\n",
    "          isTimed = False\n",
    "\n",
    "        if isRecording:\n",
    "          if id == 11:\n",
    "            recording.append((frame, round(lm.y, 1)))\n",
    "            recPose.append(results.pose_landmarks)\n",
    "\n",
    "            #monitor_val = round(lm.x, 1)\n",
    "            rec_this = round(lm.y, 1)\n",
    "\n",
    "            if monitor_val > rec_this:\n",
    "              isRecording = False\n",
    "              isTracking = segmentize(recording) \n",
    "              monitor_val = 0.01\n",
    "              isTimed = False\n",
    "              initial_time = time.time()\n",
    "\n",
    "            monitor_val = round(lm.y, 1)\n",
    "\n",
    "        if isTracking:\n",
    "          if id == 11:\n",
    "            if recording[0][1] == round(lm.y, 1):\n",
    "              isTracking = False\n",
    "              recording.append((frame, round(lm.y, 1)))\n",
    "              recPose.append(results.pose_landmarks)\n",
    "              segments.append(recording[len(recording)-1])\n",
    "              segPose.append(recPose[len(recording)-1])\n",
    "              save_imgs()\n",
    "              isRecording = False\n",
    "              isTimed = False\n",
    "              initial_time = time.time() + 1000\n",
    "              initial_time2 = time.time() + 5\n",
    "              monitor_val = 0.01\n",
    "              res = feedback(segPose)\n",
    "              recPose.clear()\n",
    "              segPose.clear()\n",
    "              if res == [True, True, True, True, True] :\n",
    "                squatPrompt = \"You have great posture\"\n",
    "              else:\n",
    "                squatPrompt = \"Please fix your posture\"\n",
    "              \n",
    "    for i in range(5):\n",
    "      y = 100 + (50 * i)\n",
    "      if not res[i]:\n",
    "        frame = cv.putText(frame, str_feed[i], (40, y ), cv.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        \n",
    "  else :\n",
    "    squatPrompt = \"Please make sure you are visible\"\n",
    "    \n",
    "  image = cv.putText(frame, squatPrompt, (40, 50), cv.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "  \n",
    "                \n",
    "    \n",
    "      \n",
    "  cv.imshow(\"Realtime\", image)\n",
    "  key = cv.waitKey(1)\n",
    "\n",
    "  if key == ord('q'):\n",
    "      key = cv.waitKey()\n",
    "      camera.release()\n",
    "      cv.destroyAllWindows()\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5741af22-470c-4f52-b445-dd079f16cf2d",
   "metadata": {},
   "source": [
    "trying = predict_imgs()\n",
    "print(trying)q"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b0dbaf3-e807-4bf7-a9eb-b1bc2fbd94ea",
   "metadata": {},
   "source": [
    "def predict(image):\n",
    "    classifier_model = \"model.h5\"\n",
    "      \n",
    "    model = load_model(classifier_model)\n",
    "      \n",
    "    test_image = image.resize((200,200))\n",
    "    test_image = preprocessing.image.img_to_array(test_image)\n",
    "    test_image = test_image / 255.0\n",
    "    test_image = np.expand_dims(test_image, axis=0)\n",
    "    class_names = {0 : 'c_bot_1', 1 :'c_mid_1', 2 :'c_top_1', 3 :'c_top_2', 4 :'i_bot_1', 5 :'i_mid_1', 6 :'i_top_1', 7 :'i_top_2'}\n",
    "    predictions = model.predict(test_image)\n",
    "    scores = tensorflow.nn.softmax(predictions[0])\n",
    "    scores = scores.numpy()\n",
    "    result = f\"{class_names[np.argmax(scores)]} with a { (100 *       np.max(scores)).round(2) } % confidence.\" \n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91e832de-1d35-4278-bc5f-118e4b284cb3",
   "metadata": {},
   "source": [
    "def predict_imgs():\n",
    "  for i in range(4):\n",
    "      img = image.load_img(f\"{dir_path}/input{i}.png\", target_size = (480, 270, 3))\n",
    "      plt.imshow(img)\n",
    "      plt.show()\n",
    "\n",
    "      X = image.img_to_array(img)\n",
    "      X = np.expand_dims(X, axis = 0)\n",
    "      images = np.vstack([X])\n",
    "\n",
    "      val = model.predict(images)\n",
    "      class_names = {0 : 'c_bot_1', 1 :'c_mid_1', 2 :'c_top_1', 3 :'c_top_2', 4 :'i_bot_1', 5 :'i_mid_1', 6 :'i_top_1', 7 :'i_top_2'}\n",
    "      scores = tensorflow.nn.softmax(val[0])\n",
    "      scores = scores.numpy()\n",
    "      result = f\"{class_names[np.argmax(scores)]} with a { (100 * np.max(scores)).round(2) } % confidence.\" \n",
    "\n",
    "\n",
    "      print(val, type(val))\n",
    "      print(result)\n",
    "      print(f\"{class_names[np.argmax(scores)]}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e671800-3008-4437-96d1-8079ec6064ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
